---
title: "Project"
author: "Anthony"
date: "April, 2024"
output:
  html_document:
    keep_md: yes
    theme: readable
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

```

### Overview

The project's goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. This is the "classe" variable in the training set. The selected prediction model will be used to predict 20 different test cases.


### Loading packages and Datasets

```{r, cache = T}

# read packages
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
set.seed(15024)


# read the datasets
df_train <-  read_csv("pml-training.csv") %>% 
  rename(X1 = `...1`)

df_test <- read_csv("pml-testing.csv") %>% 
  rename(X1 = `...1`)

```


### Data partitioning step

Because we want to estimate the _out-of-sample error_, we split the full dataset(df_train) into a training set (trainset) and a validation set (testset)

```{r, cache = T}
# split data to create trainset and testset
inTrain  <- createDataPartition(df_train$classe, p=0.7, list=FALSE) %>%
  as.data.frame() %>% rename(X1 = Resample1)

trainset <- semi_join(df_train, inTrain)
testset <- anti_join(df_train, inTrain)

```

### Data cleaning step

* Let us remove variables with near Zero variance (NZV)
* Let us delete predictors containing missing values
* Let us remove useless variables


```{r, cache = T}
NZV <- nearZeroVar(trainset)

trainset <-  trainset %>%
  select(-NZV) %>%
  select(which(colMeans(is.na(.)) == 0),
         -(1:5))

testset <- testset %>% 
  select(-NZV) %>%
  select(which(colMeans(is.na(.)) == 0),
         -(1:5))
```


Each dataset is remaining with 54 variables

#### Correlation

Let us visualize correlation among predictors left in our dataset

```{r, fig.align='center', fig.height=10, cache = T}
corMatrix <- cor(trainset[, -54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower",
         tl.cex = 0.6, tl.col = rgb(0, 0, 0))
```


---

### Modeling

Let us try to fit the following ML models to our data and see which one performs better.

* Decision Trees
* Random Forest
* Generalized Boosted Model

---

#### Decision Trees

```{r, fig.width=12, fig.height=12, cache = T}

# fitting the model
set.seed(15024)
DTree_ModFit <- rpart(classe ~ ., data=trainset, method="class")

# prediction 
DTree_predict <- predict(DTree_ModFit, newdata=testset %>% mutate(classe=as.factor(classe)), type="class")
DTree_ConfMat <- confusionMatrix(DTree_predict, as.factor(testset$classe))
DTree_ConfMat
```

From decision trees method, we have **Accuracy: 0.8127**

---

#### Random Forest

Let us try a Random Forest model and see how it performs using a 3-fold cross-validation.

```{r, cache = T}
set.seed(15024)
# Model fitting
RF_control <- trainControl(method="cv", 3)
RF_model <- train(classe ~ ., data=trainset, method="rf", trControl=RF_control, ntree=200)
RF_model$finalModel

# Prediction 
RF_predict <- predict(RF_model, newdata=testset %>% mutate(classe=as.factor(classe)))
RF_confMatrix <- confusionMatrix(RF_predict, as.factor(testset$classe))
RF_confMatrix
```

From Random Forest method, we have **Accuracy: 0.9976**

---

#### Generalized Boosted Model

Let us try a Generalized Boosted Model. 

```{r, cache = T}
set.seed(15024)

# model fitting
GBM_control <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
GBM_modFit  <- train(classe ~ ., data=trainset, method = "gbm",
                    trControl = GBM_control, verbose = FALSE)
GBM_modFit$finalModel

# prediction 
predictGBM <- predict(GBM_modFit, newdata=testset %>% mutate(classe=as.factor(classe)))
confMatGBM <- confusionMatrix(predictGBM, as.factor(testset$classe))
confMatGBM
```

From GB model, we have **Accuracy: 0.9849**

---

### Selected Model and test data

Based on performance of the three models, Random Forest model performed batter than the rest in terms of accuracy.
We use Random Forest model to predict the 20 quiz results (test dataset).

```{r, cache = T}
QuizResults <- predict(RF_model, newdata=df_test)
QuizResults


```